{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keyword extraction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhhb8Is+8IO9eERFftFjKo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Moshekwa/Text-Analytucs-Topic-Modelling-for-Power-BI/blob/main/Keyword_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm5uEpM04dml"
      },
      "source": [
        "!pip install python-rake\n",
        "!pip install --upgrade pandas\n",
        "import pandas as pd\n",
        "import RAKE\n",
        "import operator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRBM29Ha9tKW"
      },
      "source": [
        "import sys\n",
        "# !{sys.executable} -m spacy download en\n",
        "import re, numpy as np, pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "import gensim, spacy, logging, warnings\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import lemmatize, simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# NLTK Stop words\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "# stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come'])\n",
        "\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UoaBmUZ5F-d"
      },
      "source": [
        "df = pd.read_csv('/content/CSI Customer Response.csv',error_bad_lines=False)\n",
        "print(df.shape)\n",
        "df\n",
        "\n",
        "def sent_to_words(sentences):\n",
        "    for sent in sentences:\n",
        "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
        "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
        "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
        "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
        "        yield(sent)  \n",
        "\n",
        "# Convert to list\n",
        "df = df.rename(columns={'customer;': 'customer'})\n",
        "data = df.customer.values.tolist()\n",
        "data_words = list(sent_to_words(data))\n",
        "#print(df.columns)\n",
        "\n",
        "#print(df['customer'])\n",
        "\n",
        "print(data_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI04aWFe9O0C"
      },
      "source": [
        "# Clean Data Before Using Rake"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PunCXjUm6Z59"
      },
      "source": [
        "filename = '/content/CSI Customer Response.csv'\n",
        "import csv\n",
        "import re\n",
        "#next(filename) # Skip header\n",
        "\n",
        "with open(filename, 'r') as csvfile:\n",
        "    test = \"\"\n",
        "    datareader = csv.reader(csvfile)\n",
        "    for row in datareader:\n",
        "      row = listToString(row)\n",
        "      row =  re.sub(pattern = \"[^\\w\\s]\",repl = \"\",string = row) #Removes semi colon\n",
        "      row = re.sub('\\S*@\\S*\\s?', '', row)  # remove emails\n",
        "      row = re.sub('\\s+', ' ', row)  # remove newline chars\n",
        "      row = re.sub(\"\\'\", \"\", row)\n",
        "      row = row.encode('ascii', 'ignore').decode('ascii') #  strips all non-ASCII characters\n",
        "      print(row)\n",
        "'''\n",
        "# Function to convert list to string \n",
        "def listToString(s): \n",
        "    \n",
        "    # initialize an empty string\n",
        "    str1 = \"\" \n",
        "    \n",
        "    # traverse in the string  \n",
        "    for ele in s: \n",
        "        str1 += ele  \n",
        "    \n",
        "    # return string  \n",
        "    return str1 \n",
        "        \n",
        "        \n",
        "# Driver code    \n",
        "#s = ['Geeks', 'for', 'Geeks']\n",
        "print(listToString(test)) \n",
        "test1 = listToString(test)\n",
        "test =  re.sub(pattern = \"[^\\w\\s]\",repl = \"\",string = test1) #Removes semi colon\n",
        "test = re.sub('\\S*@\\S*\\s?', '', test)  # remove emails\n",
        "test = re.sub('\\s+', ' ', row)  # remove newline chars\n",
        "test = re.sub(\"\\'\", \"\", row)\n",
        "test = test.encode('ascii', 'ignore').decode('ascii') #  strips all non-ASCII characters\n",
        "\n",
        "print(test)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}