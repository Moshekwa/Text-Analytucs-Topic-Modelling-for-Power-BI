{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNrko3V/OMaTBQhWqvXUkJy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Moshekwa/Text-Analytucs-Topic-Modelling-for-Power-BI/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "5ws5bhaEFN6Q",
        "outputId": "ef179298-edab-429d-c026-a463159246ae"
      },
      "source": [
        "# 'dataset' holds the input data for this script\n",
        "import RAKE,pandas as pd, re,operator\n",
        "from textblob import TextBlob\n",
        "from textblob.sentiments import NaiveBayesAnalyzer\n",
        "\n",
        "#Add stopwords list\n",
        "stop_dir = r\"C:\\Users\\Matthews.Malatji\\Documents\\Keyword Extraction\\RAKE-tutorial\\data\\stoplists\\SmartStoplist.txt\"\n",
        "rake_object = RAKE.Rake(stop_dir)\n",
        "\n",
        "Rake_Final_Output = pd.DataFrame()\n",
        "\n",
        "#Assign your filename to a variable\n",
        "df= dataset\n",
        "\n",
        "def Sort_Tuple(tup):\n",
        "   tup.sort(key= lambda x:x[1])\n",
        "   return tup\n",
        "\n",
        "# Clean every sentence\n",
        "def clean_sentences(response):\n",
        "  response =  re.sub(pattern = \"[^\\w\\s]\",repl = \"\",string = response) #Removes semi colon\n",
        "  response = re.sub('\\S*@\\S*\\s?', '', response)  # remove emails\n",
        "  response = re.sub('\\s+', ' ', response)  # remove newline chars\n",
        "  response = re.sub(\"\\'\", \"\", response)\n",
        "  #response = re.sub(r'[0-9]+', '', response)\n",
        "  response = response.encode('ascii', 'ignore').decode('ascii') #  strips all non-ASCII characters like emojis\n",
        "  return response\n",
        "\n",
        "# Function to convert list to string \n",
        "def listToString(s): \n",
        "    # initialize an empty string\n",
        "    str1 = \"\" \n",
        "    # traverse in the string  \n",
        "    for ele in s: \n",
        "        str1 += ele  \n",
        "    # return string  \n",
        "    return str1 \n",
        "\n",
        "def get_sentiment(text):\n",
        "    #obtain polarity\n",
        "    try:\n",
        "        return TextBlob(text).sentiment.polarity\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def classify_polarity(score):\n",
        "    if score<0:\n",
        "        return 'Negative'\n",
        "    elif score==0:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return 'Positive'\n",
        "\n",
        "for x in range(len(df)):\n",
        "   responses = df.customer[x]\n",
        "   \n",
        "   #Run Rake Algorithm\n",
        "   clean = clean_sentences(responses)\n",
        "   keywords=Sort_Tuple(rake_object.run(clean))[-1:]     \n",
        "   \n",
        "   polarity_= get_sentiment(clean)\n",
        "   polarity_class = classify_polarity(polarity_)\n",
        "   \n",
        "    # create DataFrame using data    \n",
        "   Output = pd.DataFrame(keywords, columns =['Word', 'KeywordScore'])  \n",
        "\n",
        "   Output['Keywords']=keywords\n",
        "   Output['KeywordScore'] = Output['KeywordScore'].astype('float')\n",
        "\n",
        "   Output['Responses']=df.customer[x]\n",
        "   Output['Polarity']=polarity_    \n",
        "   Output['Sentiment']=polarity_class\n",
        "\n",
        "   Rake_Final_Output = Rake_Final_Output.append(Output, ignore_index=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1e38bb23104d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Customer Response'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Customer Response'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_sentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    }
  ]
}